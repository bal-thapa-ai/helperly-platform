# Helperly Backend

Production-ready FastAPI backend for Helperly - an AI-powered chatbox SaaS platform with RAG (Retrieval-Augmented Generation) capabilities.

## Features

- ğŸš€ **FastAPI** - Modern, fast web framework with automatic API docs
- ğŸ—„ï¸ **PostgreSQL + pgvector** - Vector database for semantic search
- ğŸ¤– **RAG Pipeline** - Document ingestion, chunking, embedding, and retrieval
- ğŸ” **API Key Auth** - Simple authentication (JWT ready for future)
- ğŸ¢ **Multi-tenant** - Organization-based isolation
- ğŸ“¦ **Chatboxes** - Create multiple AI chatboxes per organization
- ğŸŒ **Origin Validation** - Domain-based access control per plan
- ğŸ“ **Structured Logging** - Request tracking with correlation IDs
- ğŸ›¡ï¸ **Error Handling** - Consistent error responses with custom exceptions
- ğŸ”Œ **Pluggable Services** - Stub mode for dev without external APIs

## Quick Start

### Prerequisites

- Python 3.11+
- PostgreSQL with pgvector extension (or Supabase)
- (Optional) OpenAI API key

### Installation

1. **Clone and navigate to backend:**
   ```bash
   cd backend
   ```

2. **Create virtual environment:**
   ```bash
   python -m venv .venv
   ```

3. **Activate virtual environment:**
   - Windows:
     ```bash
     .venv\Scripts\activate
     ```
   - macOS/Linux:
     ```bash
     source .venv/bin/activate
     ```

4. **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

5. **Configure environment:**
   ```bash
   copy .env.example .env
   ```
   Edit `.env` with your settings (see Configuration section below)

6. **Run the server:**
   ```bash
   uvicorn app.main:app --reload
   ```

The API will be available at:
- **API**: http://localhost:8000
- **Interactive Docs**: http://localhost:8000/docs
- **Health Check**: http://localhost:8000/health

## Configuration

### Environment Variables

Copy `.env.example` to `.env` and configure:

#### Required for Production:
- `DATABASE_URL` - PostgreSQL connection string with asyncpg driver
- `API_KEY` - Secret key for API authentication

#### Optional (Dev Mode Works Without):
- `OPENAI_API_KEY` - For production embeddings and LLM
  - Without this, the system uses stub implementations
  - Get key from: https://platform.openai.com/api-keys

#### Other Settings:
- `ENV` - Environment: local, staging, production
- `LOG_LEVEL` - Logging level: DEBUG, INFO, WARNING, ERROR
- `CORS_ORIGINS` - Allowed CORS origins (comma-separated)
- `UPLOAD_MAX_MB` - Max file upload size (default: 7MB)
- `VECTOR_TOP_K_DEFAULT` - Number of chunks to retrieve (default: 5)
- `VECTOR_MIN_SCORE_DEFAULT` - Minimum similarity score (default: 0.7)

### Database Setup

#### Using Supabase (Recommended):

1. Create a Supabase project at https://supabase.com
2. Enable pgvector extension:
   ```sql
   CREATE EXTENSION IF NOT EXISTS vector;
   ```
3. Copy connection string from Supabase dashboard
4. Set `DATABASE_URL` in `.env`:
   ```
   DATABASE_URL=postgresql+asyncpg://postgres:[PASSWORD]@[PROJECT].supabase.co:5432/postgres
   ```

#### Using Local PostgreSQL:

1. Install PostgreSQL and pgvector
2. Create database:
   ```sql
   CREATE DATABASE helperly;
   CREATE EXTENSION vector;
   ```
3. Set `DATABASE_URL` in `.env`

## API Endpoints

### Health
- `GET /health` - Health check with database status

### Chatboxes
- `POST /v1/chatboxes` - Create a chatbox
- `GET /v1/chatboxes` - List chatboxes
- `GET /v1/chatboxes/{id}` - Get chatbox details
- `PATCH /v1/chatboxes/{id}` - Update chatbox

### Ingestion
- `POST /v1/ingest/text` - Ingest raw text
- `POST /v1/ingest/url` - Ingest from URL
- `POST /v1/ingest/upload` - Upload file (txt, pdf)

### Query
- `POST /v1/query` - Query chatbox with RAG

## Architecture

```
backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ dependencies.py      # Shared dependencies & DI
â”‚   â”‚   â””â”€â”€ routes/              # API endpoints
â”‚   â”‚       â”œâ”€â”€ health.py
â”‚   â”‚       â”œâ”€â”€ chatboxes.py
â”‚   â”‚       â”œâ”€â”€ ingest.py
â”‚   â”‚       â””â”€â”€ query.py
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ config.py            # Settings management
â”‚   â”‚   â”œâ”€â”€ database.py          # DB connection & session
â”‚   â”‚   â”œâ”€â”€ exceptions.py        # Custom exceptions
â”‚   â”‚   â”œâ”€â”€ exception_handlers.py # Global error handlers
â”‚   â”‚   â”œâ”€â”€ logging_config.py    # Structured logging
â”‚   â”‚   â””â”€â”€ middleware.py        # Request tracking
â”‚   â”œâ”€â”€ models/                  # SQLAlchemy models
â”‚   â”‚   â”œâ”€â”€ organization.py
â”‚   â”‚   â”œâ”€â”€ chatbox.py
â”‚   â”‚   â”œâ”€â”€ document.py
â”‚   â”‚   â””â”€â”€ chunk.py
â”‚   â”œâ”€â”€ repositories/            # Data access layer
â”‚   â”‚   â”œâ”€â”€ chatbox_repository.py
â”‚   â”‚   â”œâ”€â”€ document_repository.py
â”‚   â”‚   â””â”€â”€ chunk_repository.py
â”‚   â”œâ”€â”€ schemas/                 # Pydantic schemas
â”‚   â”‚   â”œâ”€â”€ chatbox.py
â”‚   â”‚   â”œâ”€â”€ ingest.py
â”‚   â”‚   â”œâ”€â”€ query.py
â”‚   â”‚   â””â”€â”€ health.py
â”‚   â”œâ”€â”€ services/                # Business logic
â”‚   â”‚   â”œâ”€â”€ embedding_service.py
â”‚   â”‚   â”œâ”€â”€ llm_service.py
â”‚   â”‚   â”œâ”€â”€ chunking_service.py
â”‚   â”‚   â”œâ”€â”€ ingestion_service.py
â”‚   â”‚   â””â”€â”€ query_service.py
â”‚   â””â”€â”€ main.py                  # FastAPI app
â”œâ”€â”€ .env.example
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## Development Mode

The backend can run without external dependencies:

- **No Database**: Health check returns "not_configured" status
- **No OpenAI Key**: Uses stub embeddings and LLM responses
- **No Auth**: Set `API_KEY=` (empty) to disable authentication

This allows rapid development and testing without setup overhead.

## Production Deployment

### Pre-deployment Checklist:

1. âœ… Set `ENV=production` in `.env`
2. âœ… Configure `DATABASE_URL` with production database
3. âœ… Set strong `API_KEY`
4. âœ… Add `OPENAI_API_KEY` for real embeddings/LLM
5. âœ… Configure `CORS_ORIGINS` with your frontend domains
6. âœ… Set `LOG_LEVEL=INFO` or `WARNING`
7. âœ… Enable pgvector extension in database
8. âœ… Create HNSW index for vector search performance:
   ```sql
   CREATE INDEX ON chunks USING hnsw (embedding vector_cosine_ops);
   ```

### Run with Uvicorn:

```bash
uvicorn app.main:app --host 0.0.0.0 --port 8000 --workers 4
```

## TODO / Future Enhancements

- [ ] **JWT Authentication** - Replace API key with JWT tokens
- [ ] **Alembic Migrations** - Database schema versioning
- [ ] **PDF Extraction** - Implement PyPDF2/pdfplumber for PDF support
- [ ] **Advanced Chunking** - Sentence-aware and semantic chunking
- [ ] **Robust Web Crawler** - Multi-page crawling with depth support
- [ ] **Rate Limiting** - Per-user/organization rate limits
- [ ] **Caching** - Redis for embeddings and query results
- [ ] **Background Jobs** - Celery for async ingestion
- [ ] **Monitoring** - Prometheus metrics and Sentry error tracking
- [ ] **Testing** - Comprehensive unit and integration tests

## Support

For issues or questions, please open an issue on the repository.

## License

Proprietary - All rights reserved
